"""
LangChain Integration Example: SQL Database Chain with MariaDB (Async)

This example demonstrates how to use async-mariadb-connector with LangChain
for SQL query generation and execution using natural language.
"""
import asyncio
import os
from typing import Any, Dict, List

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from async_mariadb_connector import AsyncMariaDB


class AsyncMariaDBLangChain:
    """
    A LangChain-compatible wrapper for AsyncMariaDB.
    Provides methods for SQL generation and execution.
    """
    
    def __init__(self):
        """Initialize the async MariaDB connection."""
        self.db = AsyncMariaDB()
        
    async def get_table_info(self, table_name: str = None) -> str:
        """
        Get schema information for tables.
        
        Args:
            table_name: Optional specific table name. If None, returns all tables.
            
        Returns:
            Formatted string with table schema information.
        """
        if table_name:
            # Get columns for specific table
            query = """
                SELECT COLUMN_NAME, COLUMN_TYPE, IS_NULLABLE, COLUMN_KEY, COLUMN_DEFAULT
                FROM INFORMATION_SCHEMA.COLUMNS
                WHERE TABLE_SCHEMA = DATABASE() AND TABLE_NAME = %s
                ORDER BY ORDINAL_POSITION
            """
            columns = await self.db.fetch_all(query, (table_name,))
            
            schema_info = f"Table: {table_name}\n"
            for col in columns:
                nullable = "NULL" if col['IS_NULLABLE'] == 'YES' else "NOT NULL"
                key = f" {col['COLUMN_KEY']}" if col['COLUMN_KEY'] else ""
                default = f" DEFAULT {col['COLUMN_DEFAULT']}" if col['COLUMN_DEFAULT'] else ""
                schema_info += f"  - {col['COLUMN_NAME']}: {col['COLUMN_TYPE']} {nullable}{key}{default}\n"
            return schema_info
        else:
            # Get all tables
            query = "SHOW TABLES"
            tables = await self.db.fetch_all(query)
            table_list = [list(t.values())[0] for t in tables]
            
            schema_info = "Available tables:\n"
            for table in table_list:
                schema_info += await self.get_table_info(table)
                schema_info += "\n"
            return schema_info
    
    async def run_query(self, sql: str) -> List[Dict[str, Any]]:
        """
        Execute a SQL query and return results.
        
        Args:
            sql: SQL query to execute
            
        Returns:
            List of dictionaries with query results
        """
        return await self.db.fetch_all(sql)
    
    async def close(self):
        """Close the database connection."""
        await self.db.close()
    
    async def __aenter__(self):
        """Context manager entry."""
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit."""
        await self.close()


async def natural_language_query_example():
    """
    Example: Use LangChain to convert natural language to SQL and execute.
    """
    print("=== Natural Language SQL Query Example ===\n")
    
    async with AsyncMariaDBLangChain() as db_chain:
        # Get schema information
        schema = await db_chain.get_table_info()
        print("Database Schema:")
        print(schema)
        
        # Example query: "Show me all users older than 30"
        # In a real implementation, you would use an LLM to generate SQL
        # For this example, we'll write the SQL directly
        
        natural_query = "Show me all users older than 30"
        print(f"\nNatural Language Query: {natural_query}")
        
        # This would normally be generated by an LLM based on the schema
        sql_query = "SELECT name, email, age FROM users WHERE age > 30"
        print(f"Generated SQL: {sql_query}\n")
        
        # Execute the query
        results = await db_chain.run_query(sql_query)
        
        print("Results:")
        for row in results:
            print(f"  - {row['name']} ({row['email']}): {row['age']} years old")


async def sql_chain_with_prompt_example():
    """
    Example: Create a simple SQL generation chain using schema context.
    """
    print("\n\n=== SQL Chain with Prompt Template ===\n")
    
    async with AsyncMariaDBLangChain() as db_chain:
        # Get schema for context
        schema = await db_chain.get_table_info("users")
        
        # Create a prompt template for SQL generation
        # Note: In production, you'd use an actual LLM (OpenAI, Claude, etc.)
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", "You are a SQL expert. Given a database schema and a question, write a SQL query."),
            ("user", "Schema:\n{schema}\n\nQuestion: {question}\n\nSQL Query:")
        ])
        
        question = "What is the average age of users?"
        
        print(f"Question: {question}\n")
        
        # For demonstration, we'll manually create the SQL
        # In production, this would be: chain = prompt_template | llm | StrOutputParser()
        sql_query = "SELECT AVG(age) as average_age FROM users"
        print(f"Generated SQL: {sql_query}\n")
        
        # Execute
        results = await db_chain.run_query(sql_query)
        print(f"Result: Average age is {results[0]['average_age']:.1f} years")


async def batch_queries_example():
    """
    Example: Execute multiple queries efficiently using async.
    """
    print("\n\n=== Batch Queries Example ===\n")
    
    async with AsyncMariaDBLangChain() as db_chain:
        queries = [
            ("Total users", "SELECT COUNT(*) as count FROM users"),
            ("Verified users", "SELECT COUNT(*) as count FROM users WHERE JSON_EXTRACT(metadata, '$.verified') = true"),
            ("Average balance", "SELECT AVG(balance) as avg_balance FROM users"),
        ]
        
        # Execute all queries concurrently
        tasks = [
            db_chain.run_query(sql)
            for _, sql in queries
        ]
        results = await asyncio.gather(*tasks)
        
        print("Statistics:")
        for (name, _), result in zip(queries, results):
            value = list(result[0].values())[0]
            if isinstance(value, float):
                print(f"  - {name}: {value:.2f}")
            else:
                print(f"  - {name}: {value}")


async def main():
    """Run all examples."""
    # Make sure MariaDB is running and populated with sample data
    # Run: docker-compose up -d
    
    await natural_language_query_example()
    await sql_chain_with_prompt_example()
    await batch_queries_example()
    
    print("\nâœ… All examples completed!")
    print("\nNote: For production use with actual LLMs, install:")
    print("  pip install langchain langchain-openai")
    print("  pip install langchain-anthropic  # or other LLM provider")


if __name__ == "__main__":
    asyncio.run(main())
